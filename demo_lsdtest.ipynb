{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "import soundfile as sf\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from dataset import CustomDataset\n",
    "\n",
    "from models.SEANet_TFiLM import SEANet_TFiLM\n",
    "from models.SEANet_TFiLM_nok import SEANet_TFiLM as SEANet_TFiLM_nok\n",
    "from models.SEANet import SEANet\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "def load_model(model, checkpoint_path):\n",
    "    model = model.to(DEVICE)\n",
    "    ckpt = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(ckpt['generator_state_dict'])\n",
    "    print(f\"Model loaded from {checkpoint_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:0 with 105051 samples\n",
      "Index:1 with 62475 samples\n",
      "LR 167526 and HR 167526 file numbers loaded!\n",
      "train: 167526 files loaded\n",
      "Index:0 with 43 samples\n",
      "LR 43 and HR 43 file numbers loaded!\n",
      "val: 43 files loaded\n",
      "torch.Size([1, 1, 674408])\n",
      "torch.Size([1, 1, 674408])\n",
      "('Alice',)\n",
      "torch.Size([1, 1, 320, 329])\n"
     ]
    }
   ],
   "source": [
    "## Load Dataset\n",
    "config_path = \"configs/K64_main.yaml\"\n",
    "config = yaml.load(open(config_path, \"r\"), Loader=yaml.FullLoader)\n",
    "test_dataset = CustomDataset(path_dir_nb=config['dataset']['nb_test'], \n",
    "                                 path_dir_wb=config['dataset']['wb_test'], seg_len=config['dataset']['seg_len'], mode=\"train\")\n",
    "\n",
    "## For USAC44 Dataset\n",
    "path_wb = [\"/home/woongjib/Projects/USAC44_mono_48k\"]\n",
    "path_nb = [\"/home/woongjib/Projects/USAC44_mono_48k_HEAAC16_LPF_Crop\"]\n",
    "test_dataset = CustomDataset(path_dir_nb=path_nb, \n",
    "                                 path_dir_wb=path_wb, seg_len=3, mode=\"val\")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "idx=13\n",
    "hr, lr, cond, name, _ = test_dataset[idx]\n",
    "\n",
    "for hr, lr, cond, name, _ in test_dataloader:\n",
    "    break\n",
    "\n",
    "print(hr.shape)\n",
    "print(lr.shape)\n",
    "print(name)\n",
    "print(cond.shape)\n",
    "\n",
    "# sf.write(\"HR.wav\", hr.squeeze().cpu().numpy(), samplerate=48000)\n",
    "# sf.write(\"LR.wav\", lr.squeeze().cpu().numpy(), samplerate=48000)\n",
    "\n",
    "# t1 = draw_spec(hr.squeeze().numpy(), figsize=(15,4), sr=48000, win_len=2048, hop_len=2048, use_colorbar=True, \n",
    "#               save_fig=True, save_path=\"hr.png\")\n",
    "# t2 = draw_spec(lr.squeeze().numpy(), figsize=(15,4), sr=48000, win_len=2048, hop_len=2048, use_colorbar=True,\n",
    "#               save_fig=True, save_path=\"lr.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woongjib/anaconda3/envs/env2/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** CHECKPOINT LOADED! **** \n",
      "Model loaded from /home/woongjib/Projects/BESSL__/ckpt_nok/epoch_13_lsdH_0.430.pth\n",
      "Model loaded from /home/woongjib/Projects/BESSL__/ckpt_baseline/epoch_43_lsdH_0.548.pth\n",
      "Alice\n",
      "Arirang_speech\n",
      "Green_speech\n",
      "HarryPotter\n",
      "KoreanM1\n",
      "Music_1\n",
      "Music_2\n",
      "Music_3\n",
      "Music_4\n",
      "Music_5\n",
      "\n",
      "Average LSD for the 20 samples: 0.510\n",
      "Average LSD base for the 20 samples: 0.664\n",
      "Average LSD nb for the 20 samples: 0.956\n"
     ]
    }
   ],
   "source": [
    "## Load Model\n",
    "# model = SEANet_TFiLM(kmeans_model_path=config['model']['kmeans_path'])\n",
    "# model = load_model(model, \"/home/woongjib/Projects/BESSL__/ckpt_K64/epoch_41_lsdH_0.441.pth\")\n",
    "\n",
    "model = SEANet_TFiLM_nok(kmeans_model_path=config['model']['kmeans_path'])\n",
    "model = load_model(model, \"/home/woongjib/Projects/BESSL__/ckpt_nok/epoch_13_lsdH_0.430.pth\")\n",
    "\n",
    "model_base = SEANet()\n",
    "model_base = load_model(model_base, \"/home/woongjib/Projects/BESSL__/ckpt_baseline/epoch_43_lsdH_0.548.pth\")\n",
    "\n",
    "## Loop\n",
    "lsd_list = []\n",
    "lsd_list_b = []\n",
    "lsd_list_nb = []\n",
    "\n",
    "for idx in range(10):\n",
    "    wb, nb, cond, name, _ = test_dataset[idx]\n",
    "    print(name)\n",
    "    with torch.no_grad():\n",
    "        recon = model(nb.to(DEVICE), cond.to(DEVICE))\n",
    "        recon_b = model_base(nb.to(DEVICE), cond.to(DEVICE))\n",
    "        \n",
    "        a = lsd_batch(wb.cpu(), recon.cpu(), fs=48000)\n",
    "        b = lsd_batch(wb.cpu(), recon_b.cpu(), fs=48000)\n",
    "        c = lsd_batch(wb.cpu(), nb.cpu(), fs=48000)\n",
    "        \n",
    "        lsd_list.append(a)\n",
    "        lsd_list_b.append(b)\n",
    "        lsd_list_nb.append(c)\n",
    "        \n",
    "        sf.write(f\"outputs/{name}_bwe.wav\", recon.squeeze().cpu().numpy(), samplerate=48000)\n",
    "        sf.write(f\"outputs/{name}_bwe_base.wav\", recon_b.squeeze().cpu().numpy(), samplerate=48000)\n",
    "        sf.write(f\"outputs/{name}_gt.wav\", wb.squeeze().cpu().numpy(), samplerate=48000)\n",
    "        \n",
    "average_lsd = sum(lsd_list) / len(lsd_list)\n",
    "average_lsd_b = sum(lsd_list_b) / len(lsd_list)\n",
    "average_lsd_nb = sum(lsd_list_nb) / len(lsd_list)\n",
    "\n",
    "print(f\"\\nAverage LSD for the 20 samples: {average_lsd:.3f}\")\n",
    "print(f\"Average LSD base for the 20 samples: {average_lsd_b:.3f}\")\n",
    "print(f\"Average LSD nb for the 20 samples: {average_lsd_nb:.3f}\")\n",
    "\n",
    "# display(Audio(wb.cpu().numpy(), rate=48000))\n",
    "# display(Audio(recon.squeeze().cpu().numpy(), rate=48000))\n",
    "# display(Audio(recon_b.squeeze().cpu().numpy(), rate=48000))\n",
    "# display(Audio(nb.cpu().numpy(), rate=48000))\n",
    "\n",
    "# t1 = draw_spec(wb.squeeze().numpy(), figsize=(15,4), sr=48000, win_len=2048, hop_len=2048, use_colorbar=True, \n",
    "#               save_fig=True, save_path=\"hr\")\n",
    "# t2 = draw_spec(recon.squeeze().cpu().numpy(), figsize=(15,4), sr=48000, win_len=2048, hop_len=2048, use_colorbar=True,\n",
    "#               save_fig=True, save_path=\"bwe\")\n",
    "# t2 = draw_spec(recon_b.squeeze().cpu().numpy(), figsize=(15,4), sr=48000, win_len=2048, hop_len=2048, use_colorbar=True,\n",
    "#               save_fig=True, save_path=\"bwe_b\")\n",
    "# t3 = draw_spec(nb.squeeze().cpu().numpy(), figsize=(15,4), sr=48000, win_len=2048, hop_len=2048, use_colorbar=True,\n",
    "#               save_fig=True, save_path=\"lr\")    \n",
    "\n",
    "# sf.write(\"bwe.wav\", recon.squeeze().cpu().numpy(), samplerate=48000)\n",
    "# sf.write(\"bwe_b.wav\", recon_b.squeeze().cpu().numpy(), samplerate=48000)\n",
    "\n",
    "# 15425536831381643598\n",
    "## 8495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
